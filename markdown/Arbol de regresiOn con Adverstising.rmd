---
title: "Arbol de regresión con Adverstising"
author: "Rubén Pizarro Gurrola"
date: "19/3/2022"
output: html_document
bibliography: referencias.bib
---

# Objetivo

Crear y evaluar un modelo de árbol de regresión para predecir Sales a partir de TV, Radio, News y Web

# Descripción

-   Cargar librerías y datos Advertising
-   Limpiar datos si es necesario
-   Explorar datos
-   Partir los datos en datos de entrenamiento y datos de validación 70% y 30%
-   Crear modelo de regresión con los daos de entrenamiento
-   Evaluar modelo antes de predicciones con los estadísticos. R Square y Coeficientes. **No aplica**
-   Predicciones con datos de validación
-   Evaluar predicciones con respecto a *rmse*
-   Comparar contra el modelo de regresión múltiple con la métrica *rmse* y observar cuál es más bajo.
-   Evaluar que tanto valor estadístico existe de correlación lineal (*Pearson*) entre valores predichos y reales o viceversa.
-   Interpretar el caso

# Fundamento teórico

Los algoritmos de aprendizaje basados en árbol se consideran uno de los mejores y más utilizados métodos de aprendizaje supervisado.

Potencian modelos predictivos con alta precisión, estabilidad y facilidad de interpretación.

Los árboles de clasificación y regresión son métodos que proporcionan modelos que satisfacen objetivos tanto predictivos como explicativos.

Algunas ventajas son su sencillez y la representación gráfica mediante árboles y, por otro, la definición de reglas de asociación entre variables que incluye expresiones de condición que permiten explicar las predicciones.

Se pueden usar para regresiones con variables dependientes que tienen valores numéricos continuos o para clasificaciones con variables categóricas.

Utilizar un árbol de regresión para crear un modelo explicativo y predictivo para una variable cuantitativa dependiente basada en variables explicativas independientes cuantitativas y cualitativas [@xlstatbyaddinsoft]

Un árbol de regresión consiste en hacer preguntas de tipo$¿x_k < c?$ para cada una de las covariables, de esta forma el espacio de las covariables es divido en hiper-rectángulos (con el resultado de las condicionales) de las observaciones que queden dentro de un hiper-rectángulo tendrán el mismo valor estimado $\hat{y}$ o $Y$ [@hernández2021].

Por otra parte, bajo el paradigma divide y vencerás, usando árboles de regresión y decisión y correspondientes reglas, el árbol representa el modelo similar a un diagrama de flujo en el que los nodos de decisión, los nodos de hoja y las ramas definen una serie de decisiones que se pueden usar para generar predicciones. Siguiendo las reglas se encuentran predicciones en la hoja final. [@lantz2013].

# Desarrollo

## Cargar librerías

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
# library(plotly) # no se está usando
library(knitr)
library(PerformanceAnalytics) # Para coorelaciones gráficas
library(caret)  # Para particionar
library(Metrics) # Para determinar rmse
library(PerformanceAnalytics) # Para
library(rpart)       # arboles
library(rpart.plot)  # arboles visuales

library(PerformanceAnalytics) # Para cor grafica
```

## Cargar datos

```{r}
datos <- read.csv("https://raw.githubusercontent.com/rpizarrog/Machine-Learning-con-R/main/datos/Advertising_Web.csv")
```

## Explorar datos

```{r}
str(datos)
summary(datos)
```

### Limpiar datos

Quitar las primeras columnas

```{r}
datos <- select(datos, TV, Radio, Newspaper, Web, Sales)

```

### Correlaciones lineal entre variables

```{r}
cor(datos)
```

```{r}
chart.Correlation(datos)
```

### Las variables de interés

-   x's las variable independientes o predictoras son TV, Radio, Newspaper y Web
-   y la variable dependiente o resultado (Sales), es decir y depende de x's.

## Limpiar datos

En caso necesario. No se observan datos extraños .... porque son pocos.

## Partir datos

Aleatoriamente se reparten las observaciones con el 70% para datos de entrenamiento y el 30% para datos de validación.

Sembrar una semilla con set.seed()

```{r}
set.seed(2022)
```

```{r}
n <- nrow(datos)  # cantidad de observaciones
```

```{r}
entrena <- createDataPartition(y = datos$Sales, p = 0.70, list = FALSE, times = 1)

# Datos entrenamiento
datos.entrenamiento <- datos[entrena, ]  # [renglones, columna]

# Datos validación
datos.validacion <- datos[-entrena, ]
```

### Datos de entrenamiento

```{r}
datos.entrenamiento
```

### Datos de validación

```{r}
datos.validacion
```

## Construir el modelo

El modelo se construye con datos de entrenamiento

Arbol de Regresión con variables numéricas

```{r}
modelo_ar <- rpart(data = datos.entrenamiento, formula = Sales ~ TV + Radio + Newspaper + Web)
summary(modelo_ar)

```

## Representar visualmente el árbol de regresión

```{r}
rpart.plot(modelo_ar)
```

## Hacer predicciones

```{r}
predicciones <- predict(object = modelo_ar, newdata = datos.validacion)
# predicciones
```

Construir un *data frame* para comparar

```{r}
comparaciones <- data.frame(datos.validacion, predicciones)
comparaciones
```

## Evaluar predicciones

*rmse* Root Mean Stándard Error (*Root-mean-square deviation*), este valor normalmente se compara contra otro modelo y el que esté mas cerca de cero es mejor.

La raiz del Error Cuadrático Medio (*rmse*) es una métrica que dice qué tan lejos están los valores predichos de los valores observados o reales en un análisis de regresión, en promedio. Se calcula como:

$$
rmse = \sqrt{\frac{\sum(predicho_i - real_i)^{2}}{n}}
$$

*RMSE* es una forma útil de ver qué tan bien un modelo de regresión puede ajustarse a un conjunto de datos.

Cuanto mayor sea el *rmse*, mayor será la diferencia entre los valores predichos y reales, lo que significa que peor se ajusta un modelo de regresión a los datos. Por el contrario, cuanto más pequeño sea el *rmse*, mejor podrá un modelo ajustar los datos.

### Evaluando con rmse

En el modelo de regresión múltiple <https://rpubs.com/rpizarro/879843> con los datos Adverstising se tuvo un valor de *rmse* de: 1.470771.

Con este modelo de árbol de regresión, los mismos datos, mismas particiones se tuvo un valor de 1.455681 por lo que se puede interpretar que este modelo de regresión fué mejor con respecto a la métrica *rmse*.

```{r}
rmse <- rmse(actual = comparaciones$Sales, predicted = comparaciones$predicciones)
rmse
```

### Evaluando con la correlación 

Se puede evaluar con la correlación lineal de los valores predichos contra los valores relaes o viceversa.

```{r}
chart.Correlation(R = comparaciones[, c('Sales', 'predicciones')], histogram = TRUE)

```

Se observa una **muy fuerte** correlación entre las predicciones contra los valores reales (Sales) y viceversa de 0.95.

## Visualizar predicciones contra valores reales

```{r}
ggplot(data = comparaciones) +
  geom_line(aes(x = 1:nrow(comparaciones), y = Sales), col='blue') +
  geom_line(aes(x = 1:nrow(comparaciones), y = predicciones), col='yellow') +
  ggtitle(label="Valores reales vs predichos Adverstising", subtitle = "Arbol de Regresión") 
  
  
```

## Predicciones con datos nuevos

```{r}
TV <- c(140, 160)
Radio <- c(60, 40)
Newspaper <- c(80, 90) 
Web <- c(120, 145)
  
nuevos <- data.frame(TV, Radio, Newspaper, Web)  
nuevos

Y.predicciones <- predict(object = modelo_ar, newdata = nuevos)
Y.predicciones
```

# Interpretación

# Bibliografía
